{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee67cb4-7b87-42ef-90bf-f49556757b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0918c77c-de8e-444f-97ca-6360f42f812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\midohossam\\AppData\\Local\\Temp\\ipykernel_9808\\2136592268.py:7: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df[\"Formatted Date\"] = pd.to_datetime(df[\"Formatted Date\"])\n"
     ]
    }
   ],
   "source": [
    "path = r\"../data/weatherHistory.csv\"\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# 2. Parse and sort by date\n",
    "df[\"Formatted Date\"] = pd.to_datetime(df[\"Formatted Date\"])\n",
    "df = df.sort_values(\"Formatted Date\").reset_index(drop=True)\n",
    "\n",
    "# Keep only needed columns for now\n",
    "df = df[[\"Formatted Date\", \"Temperature (C)\", \"Summary\", \"Precip Type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3e6d8d-7e5f-4bfc-8ff4-9f5e8efe54e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96453 entries, 0 to 96452\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Formatted Date   96453 non-null  object \n",
      " 1   Temperature (C)  96453 non-null  float64\n",
      " 2   Summary          96453 non-null  object \n",
      " 3   Precip Type      95936 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f182e7e-890c-4c2a-befa-b413d363b4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Formatted Date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Temperature (C)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Precip Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "fa9fd6fc-a560-4ee7-ac9c-8904de791bd2",
       "rows": [
        [
         "0",
         "2006-01-01 00:00:00+01:00",
         "0.5777777777777773",
         "Partly Cloudy",
         "rain"
        ],
        [
         "1",
         "2006-01-01 01:00:00+01:00",
         "1.161111111111113",
         "Mostly Cloudy",
         "rain"
        ],
        [
         "2",
         "2006-01-01 02:00:00+01:00",
         "1.6666666666666667",
         "Mostly Cloudy",
         "rain"
        ],
        [
         "3",
         "2006-01-01 03:00:00+01:00",
         "1.71111111111111",
         "Overcast",
         "rain"
        ],
        [
         "4",
         "2006-01-01 04:00:00+01:00",
         "1.183333333333335",
         "Mostly Cloudy",
         "rain"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formatted Date</th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Precip Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01 00:00:00+01:00</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-01 01:00:00+01:00</td>\n",
       "      <td>1.161111</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-01 02:00:00+01:00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-01 03:00:00+01:00</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-01 04:00:00+01:00</td>\n",
       "      <td>1.183333</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Formatted Date  Temperature (C)        Summary Precip Type\n",
       "0  2006-01-01 00:00:00+01:00         0.577778  Partly Cloudy        rain\n",
       "1  2006-01-01 01:00:00+01:00         1.161111  Mostly Cloudy        rain\n",
       "2  2006-01-01 02:00:00+01:00         1.666667  Mostly Cloudy        rain\n",
       "3  2006-01-01 03:00:00+01:00         1.711111       Overcast        rain\n",
       "4  2006-01-01 04:00:00+01:00         1.183333  Mostly Cloudy        rain"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc07862-882e-459d-b314-c4fb01c5cd99",
   "metadata": {},
   "source": [
    "We will use Temperature (C) as the observation and convert it to 3 categories:\n",
    "\n",
    "0 → Cold\n",
    "\n",
    "1 → Mild\n",
    "\n",
    "2 → Hot\n",
    "\n",
    "For example:\n",
    "\n",
    "Temp < 10°C → Cold (0)\n",
    "\n",
    "10°C ≤ Temp < 20°C → Mild (1)\n",
    "\n",
    "Temp ≥ 20°C → Hot (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9fa792-6de6-49f2-be08-21ae939b3ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs\n",
      "0    42436\n",
      "1    33340\n",
      "2    20677\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def temp_to_obs(t):\n",
    "    if t < 10:\n",
    "        return 0   # Cold\n",
    "    elif t < 20:\n",
    "        return 1   # Mild\n",
    "    else:\n",
    "        return 2   # Hot\n",
    "\n",
    "df[\"Obs\"] = df[\"Temperature (C)\"].apply(temp_to_obs)\n",
    "\n",
    "# Check distribution of observations\n",
    "print(df[\"Obs\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5749fd-cf38-46d2-bc01-3d94d4ba4936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of observation sequence: 96453\n",
      "First 20 observations: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Observation sequence as integers\n",
    "O = df[\"Obs\"].to_numpy(dtype=int)\n",
    "\n",
    "print(\"Total length of observation sequence:\", len(O))\n",
    "print(\"First 20 observations:\", O[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d2caff5-9287-4f53-ad22-94a3bcb58d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 67517\n",
      "Test length: 28936\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.7\n",
    "split_idx = int(train_ratio * len(O))\n",
    "\n",
    "O_train = O[:split_idx]\n",
    "O_test  = O[split_idx:]\n",
    "\n",
    "print(\"Train length:\", len(O_train))\n",
    "print(\"Test length:\", len(O_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410b0e2",
   "metadata": {},
   "source": [
    "## **2. Model Assumption And Initialization of Matrices**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37be1d",
   "metadata": {},
   "source": [
    "### **Normalization of HMM Parameter Matrices**\n",
    "#### **Ensuring π, A, and B Rows Form Valid Probability Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71d62de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rows(mat, eps=1e-12):\n",
    "    # rows to sum to 1\n",
    "    row_sums = mat.sum(axis=1, keepdims=True)\n",
    "    row_sums[row_sums == 0] = eps\n",
    "    return mat / row_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae85965",
   "metadata": {},
   "source": [
    "### **Initialization functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcde808-a4a4-4d32-8242-3f73e761d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_uniform(N, M):\n",
    "    pi = np.ones(N) / N\n",
    "    A = np.ones((N, N)) / N\n",
    "    B = np.ones((N, M)) / M\n",
    "    return pi, A, B\n",
    "\n",
    "def init_dirichlet(N, M, alpha_pi=1.0, alpha_A=1.0, alpha_B=1.0, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # pi: length N\n",
    "    pi = rng.dirichlet([alpha_pi]*N)\n",
    "    # A: N x N (each row a distribution)\n",
    "    A = np.vstack([rng.dirichlet([alpha_A]*N) for _ in range(N)])\n",
    "    # B: N x M\n",
    "    B = np.vstack([rng.dirichlet([alpha_B]*M) for _ in range(N)])\n",
    "    return pi, A, B\n",
    "\n",
    "def init_with_self_bias(N, M, self_prob=0.6):\n",
    "    \"\"\"Initialize A with a bias to remain in the same state.\"\"\"\n",
    "    if not (0 <= self_prob <= 1):\n",
    "        raise ValueError(\"self_prob must be between 0 and 1\")\n",
    "    off_prob = (1.0 - self_prob) / (N - 1) if N>1 else 0.0\n",
    "    A = np.full((N, N), off_prob)\n",
    "    np.fill_diagonal(A, self_prob)\n",
    "    pi = np.ones(N) / N\n",
    "    B = np.ones((N, M)) / M\n",
    "    return pi, A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0171ec",
   "metadata": {},
   "source": [
    "### **Initialization from Labeled Sequences**\n",
    "#### **-Supervised Estimation of HMM Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_from_labeled_sequences(labeled_sequences, N, M, smoothing=1.0):\n",
    "    \"\"\"\n",
    "    labeled_sequences: list of sequences. Each sequence is (states, obs) where\n",
    "      states: list of ints in [0..N-1]\n",
    "      obs: list of ints in [0..M-1]\n",
    "    Returns: pi, A, B (with Laplace smoothing)\n",
    "    \"\"\"\n",
    "    pi_counts = np.zeros(N)\n",
    "    A_counts = np.zeros((N, N))\n",
    "    B_counts = np.zeros((N, M))\n",
    "\n",
    "    for states, obs in labeled_sequences:\n",
    "        if len(states) == 0:\n",
    "            continue\n",
    "        pi_counts[states[0]] += 1\n",
    "        for t in range(len(states)):\n",
    "            s = states[t]\n",
    "            o = obs[t]\n",
    "            B_counts[s, o] += 1\n",
    "            if t+1 < len(states):\n",
    "                A_counts[s, states[t+1]] += 1\n",
    "\n",
    "    # Add smoothing and normalize\n",
    "    pi = (pi_counts + smoothing) / (pi_counts.sum() + smoothing * N)\n",
    "    A = (A_counts + smoothing) / (A_counts.sum(axis=1, keepdims=True) + smoothing * N)\n",
    "    B = (B_counts + smoothing) / (B_counts.sum(axis=1, keepdims=True) + smoothing * M)\n",
    "\n",
    "    return pi, A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e123822",
   "metadata": {},
   "source": [
    "### **Initialization from Observations Using K-Means Clustering**\n",
    "#### **-Unsupervised Approximation for Emission Probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_from_observations_kmeans(observations, N, M, kmeans_labels, smoothing=1.0):\n",
    "    \"\"\"\n",
    "    observations: list/array of observation indices (0..M-1)\n",
    "    kmeans_labels: array of length len(observations) with labels in 0..N-1\n",
    "    This is a helper if you precomputed clustering (KMeans on feature vectors).\n",
    "    \"\"\"\n",
    "    # convert sequence-like grouping if needed\n",
    "    # Here we assume a single long sequence\n",
    "    pi_counts = np.zeros(N)\n",
    "    A_counts = np.zeros((N, N))\n",
    "    B_counts = np.zeros((N, M))\n",
    "\n",
    "    if len(kmeans_labels) == 0:\n",
    "        return init_dirichlet(N, M)\n",
    "\n",
    "    pi_counts[kmeans_labels[0]] += 1\n",
    "    for t in range(len(kmeans_labels)):\n",
    "        s = kmeans_labels[t]\n",
    "        o = observations[t]\n",
    "        B_counts[s, o] += 1\n",
    "        if t+1 < len(kmeans_labels):\n",
    "            A_counts[s, kmeans_labels[t+1]] += 1\n",
    "\n",
    "    pi = (pi_counts + smoothing) / (pi_counts.sum() + smoothing * N)\n",
    "    A = (A_counts + smoothing) / (A_counts.sum(axis=1, keepdims=True) + smoothing * N)\n",
    "    B = (B_counts + smoothing) / (B_counts.sum(axis=1, keepdims=True) + smoothing * M)\n",
    "    return pi, A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f592c",
   "metadata": {},
   "source": [
    "### **Validation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a952d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_pi_A_B(pi, A, B, tol=1e-9):\n",
    "    ok = True\n",
    "\n",
    "    if not np.allclose(pi.sum(), 1.0, atol=tol):\n",
    "        print(f\"Warning: pi does not sum to 1 (sum={pi.sum()})\")\n",
    "        ok = False\n",
    "\n",
    "    if not np.allclose(A.sum(axis=1), np.ones(A.shape[0]), atol=tol):\n",
    "        print(f\"Warning: some rows of A do not sum to 1 (row sums={A.sum(axis=1)})\")\n",
    "        ok = False\n",
    "\n",
    "    if not np.allclose(B.sum(axis=1), np.ones(B.shape[0]), atol=tol):\n",
    "        print(f\"Warning: some rows of B do not sum to 1 (row sums={B.sum(axis=1)})\")\n",
    "        ok = False\n",
    "\n",
    "    return ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf66058",
   "metadata": {},
   "source": [
    "### **Generate & validate π, A, B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a382259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform A:\n",
      " [[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]]\n",
      "Uniform B:\n",
      " [[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "Dirichlet pi:\n",
      " [0.33742524 0.32787894 0.33469582]\n"
     ]
    }
   ],
   "source": [
    "N = 3   # hidden states\n",
    "M = 4   # observation symbols\n",
    "pi_u, A_u, B_u = init_uniform(N, M)\n",
    "pi_r, A_r, B_r = init_dirichlet(N, M, alpha_pi=1.0, alpha_A=1.0, alpha_B=1.0, seed=42)\n",
    "print(\"Uniform A:\\n\", A_u)\n",
    "print(\"Uniform B:\\n\", B_u)\n",
    "print(\"Dirichlet pi:\\n\", pi_r)\n",
    "assert validate_pi_A_B(pi_r, A_r, B_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a04027b",
   "metadata": {},
   "source": [
    "## **Member3 -> GOOD LUCK :)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
